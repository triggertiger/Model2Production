{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Notebook\n",
    "this notebook is focusing on understanding the data and its structure. \n",
    "\n",
    "> note: for convenience, the first 2 cellblocks are to be seen before the imports, as to avoid running long code by mistake. The data is then saved in a smaller .csv file, which is used for the model training and predictions. \n",
    "\n",
    "First version of the model is created for testing purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: \n",
    "https://www.kaggle.com/datasets/ealtman2019/credit-card-transactions?resource=download&select=credit_card_transactions-ibm_v2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is too large, for loading on small RAM use chunk\n",
    "chunk = 10000\n",
    "dflist = []\n",
    "for df in pd.read_csv('./data/cc_ibm.csv', chunksize=chunk):\n",
    "    dflist.append(df)\n",
    "\n",
    "# create a large dataframe\n",
    "ibm = pd.concat(dflist)\n",
    "ibm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2002, 2021)\n",
    "dfs = []\n",
    "\n",
    "# sort out the relevant years: 4 years from the last period\n",
    "for year in years[13:]:\n",
    "    df = ibm.loc[ibm['Year'] == year]\n",
    "    dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it for later (the original file is very large)\n",
    "data = pd.concat(dfs[-6:])\n",
    "data.to_csv('ibm_6y.csv', index=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ibm_4y.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCC codes are four-digit numbers that classify a business by the services it provides or products it sells. If a business has a variety of products or services, the MCC code is usually based on the product or service that makes up the bulk of the businessâ€™ sales. (https://www.heartland.us/resources/blog/merchants-guide-to-mcc-codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(str.lower, axis='columns', inplace=True)\n",
    "data.rename(columns={'use chip': 'use_chip', \n",
    "                       'merchant name': 'merchant_name', \n",
    "                       'merchant city': 'merchant_city', \n",
    "                       'merchant state': 'merchant_state',\n",
    "                       'errors?': 'errors', \n",
    "                       'is fraud?': 'is_fraud' }, \n",
    "                       inplace=True)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set time series index\n",
    "data[['hour', 'minute']] = data['time'].str.split(':', expand=True)\n",
    "data['date'] = pd.to_datetime(data[['year', 'month', 'day', 'hour', 'minute']])\n",
    "data.set_index('date', inplace=True)\n",
    "#data.drop(columns=['year', 'month', 'day', 'time', 'hour', 'minute'], inplace=True)\n",
    "\n",
    "# convert amount to float\n",
    "data['amount'] = data['amount'].str[1:].astype('float64')\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the dates are sequential:\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize= (8, 4))\n",
    "ax1.plot(data['year'])\n",
    "ax2.plot(data['month'])\n",
    "ax3.plot(data['day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the charts, the years and months are sequential, \n",
    "# however the dates inside every single month are mixed up. \n",
    "data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize= (8, 4))\n",
    "ax1.plot(data['year'])\n",
    "ax2.plot(data['month'])\n",
    "ax3.plot(data['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[ 'time'], inplace=True)\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of fraud transactions: 4,833\n",
    "data.loc[data['is_fraud'] == 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many missing values in errors: most of the transactions are without errors.\n",
    "data['errors'].value_counts()       #total 87K errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check connection between errors, error types, and frauds:\n",
    "data['errors'].loc[data['is_fraud'] == 'Yes' ].groupby(data['errors'].loc[data['is_fraud'] == 'Yes' ].index.year).value_counts()\n",
    "\n",
    "\n",
    "# no significant correlation between fraud/errors, errors are of different kinds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['user'].groupby(data.index.year).agg('count')\n",
    "# 2020 only until 03-2020 - beginning of Covid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check transaction type (use_chip)\n",
    "data.groupby([data.index.year, 'use_chip'])['use_chip'].value_counts()  \n",
    " \n",
    "# about same % of online transactions from total as other years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the merchant state missing values are online transactions. \n",
    "data.loc[data['merchant_state'].isna()].groupby('merchant_city').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# online transactions have no zipcode and no state. \n",
    "# a bit over 12% [4.7K/38K] of the transactions are fraud with missing zipcode but on premise. \n",
    "data.loc[(data['zip'].isna() == True) & (data['merchant_state'].isna() == False)].groupby('is_fraud').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to the fraud rate from the total transactions:\n",
    "\n",
    "data['is_fraud'].value_counts() / data.shape[0]\n",
    "# many more frauds without zip code (but not online) than in the total dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['zip'].isna() == True)& (data['merchant_state'].isna() == False)].nunique()    \n",
    "# more than half the users have deals without zip code, through the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the fraud cases without zip codes come from Rome, Italy\n",
    "no_zip = data.loc[(data['zip'].isna() == True)& (data['merchant_state'].isna() == False)]\n",
    "cities_with_no_zip = []\n",
    "cities_with_other_zips = []\n",
    "for city in no_zip['merchant_city'].value_counts().index:\n",
    "    x = data.loc[data['merchant_city'] == city]['zip'].nunique()\n",
    "    f = data.loc[data['merchant_city'] == city]['is_fraud'].value_counts()\n",
    "    if 'Yes' in f.index:\n",
    "         print(f)\n",
    "         print(f'{city}: different zips: {x}')\n",
    "    if x == 0:\n",
    "         cities_with_no_zip.append(x)\n",
    "    else:\n",
    "         cities_with_other_zips.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_zip.loc[no_zip['merchant_city'] == 'Rome'].groupby('is_fraud').count()\n",
    "\n",
    "# there's also Rome city in NY. all the zip codes from Rome, It are NA. \n",
    "# total deals from rome for the yesrs: 5,700. so most of the data fro Rome is Fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['merchant_city'] == 'Rome') & (data.index.year == 2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['merchant_city'] != 'Rome') & (data['merchant_state'] == 'Italy') & (data['zip'].isna() == False)]\n",
    "# no other cities in Italy in the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['amount'].groupby(data['is_fraud']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(12, 6))\n",
    "plt.plot(data['amount'])\n",
    "plt.title('amount per transaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = data.loc[data['is_fraud'] == 'Yes']\n",
    "normal = data.loc[data['is_fraud'] == 'No']\n",
    "fig, axs = plt.subplots(2, 1, sharex=False, figsize= (8, 8))\n",
    "fig.suptitle('Amount per transaction by fraudulance')\n",
    "axs[0].hist(fraud['amount'], bins = 50)\n",
    "axs[0].set_title('Fraudulant transactions')\n",
    "axs[0].set_ylabel('number of trnsactions')\n",
    "\n",
    "axs[1].hist(normal['amount'], bins = 200)\n",
    "axs[1].set_title('Legit transactions')\n",
    "axs[1].set_ylabel('number of trnsactions')\n",
    "fig.text(0.5, 0.01, 'Transaction amount', ha='center', va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['amount'] < 0.1) & (data['is_fraud'] == 'Yes' )]     # 276K transactions with negative amounts, 178 are fraud. \n",
    "normal['amount'].nlargest(5)              # there are several transactions with very large amounts of >5K that make the hist seem empty. fraud: max - 1442"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['amount'].groupby(data['user']).sum()\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, figsize= (8, 8))\n",
    "fig.suptitle('Amount per transaction by fraudulance')\n",
    "axs[0].plot( fraud['amount'].groupby(fraud['user']).sum())\n",
    "axs[0].set_title('Fraudulant transactions')\n",
    "axs[1].plot(normal['amount'].groupby(normal['user']).sum())\n",
    "axs[1].set_title('Honest transactions')\n",
    "\n",
    "fig.supxlabel('User_id')\n",
    "fig.supylabel('Aggregated amount per user')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud accross time\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.scatter(normal.index, normal['amount'], color='g', alpha=0.2, label='normal transacitons')\n",
    "ax.legend(\"Honest transactions\")\n",
    "ax.scatter(fraud.index, fraud['amount'],color='r', alpha=0.05, label='fraud transactions')\n",
    "ax.legend()\n",
    "fig.suptitle('Amount per transaction for fraud and honest transactions')\n",
    "fig.supxlabel('Date')\n",
    "fig.supylabel('Transaction amount')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17, 4))\n",
    "fig.suptitle('Fraud patterns relative to normal deal patterns')\n",
    "ax.plot(fraud['amount'],color='r', alpha=0.9, label='Fraud')\n",
    "ax.plot(normal['amount'], color='g', alpha=0.2, label='Normal')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of transactions per month, legit and fraud\n",
    "m_fraud = fraud[['amount']].groupby([fraud.index.month.rename('month'), fraud.index.year.rename('year')]).count()\n",
    "m_normal = normal[['amount']].groupby([normal.index.month.rename('month'), normal.index.year.rename('year')]).count()\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.hist(m_fraud, bins=m_fraud.shape[0], color='r')\n",
    "ax.hist(m_normal, bins=m_normal.shape[0], color='g', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users with more than one fraud: \n",
    "f_users = fraud[['user', 'amount']].groupby('user').count()\n",
    "check_users = normal[['user', 'amount']].groupby('user').count()\n",
    "norm_users = normal[['user', 'amount']].loc[normal['user'].isin(f_users.index) == True].groupby('user').count()\n",
    "f = plt.subplots(figsize=(18, 4))\n",
    "plt.title('Count of fraud per user')\n",
    "plt.xlabel('user ID')\n",
    "plt.ylabel('number of transactions transactions')\n",
    "plt.bar(height=norm_users['amount'], x=norm_users.index, color='g', width=5, label='normal')\n",
    "plt.bar(height=f_users['amount'], x=f_users.index, color='r', width=5, label='fraudulant')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f_users.rename(columns={'amount': 'f_amount'}, inplace=True)\n",
    "f_users\n",
    "f_users['h_amount'] = norm_users['amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(17,6)) \n",
    "\n",
    "ax = fig.add_subplot(1,1,1) # Create matplotlib axes\n",
    "ax2 = ax.twinx() # Create another axes that shares the same x-axis as ax.\n",
    "fig.suptitle(\"correlation of number of legit/fraud transaction by user\")\n",
    "width = 0.4\n",
    "\n",
    "f_users.h_amount.plot(kind='bar', color='green', ax=ax, width=width, position=1)\n",
    "f_users.f_amount.plot(kind='bar', color='red', ax=ax2, width=width, position=0)\n",
    "\n",
    "ax.set_ylabel('legit transactions per user')\n",
    "ax2.set_ylabel('number of fraud transactions per user')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_users.shape, f_users.shape, check_users.shape, normal.shape, fraud.shape, data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - coding and normalizing \n",
    "\n",
    "Train tess split: since 2020 is not a full year, test data will be taken out of 2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['is_fraud'])\n",
    "y = data[['is_fraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, \n",
    "                                                y, \n",
    "                                                test_size=0.25, \n",
    "                                                random_state=42, \n",
    "                                                shuffle=True, \n",
    "                                                stratify=y)     #test size default 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "# replace missing values with a constant text, then encode to numeric classes and scale\n",
    "state_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='online')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# replace missing values with zero, then encode and scale\n",
    "zero_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# implement number scaler on numerical features (no missing values)\n",
    "# implement text replacement to state and errors\n",
    "# implement zero replacement to zip, city and chip\n",
    "transformer= ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('number_scaler', StandardScaler(), [0, 1, 2, 3, 4, 5, 7, 11, 13, 14]),\n",
    "        ('NAN_replace_text', state_pipe, [9, 12]),\n",
    "        ('NAN_replace_zero', zero_pipe, [6, 8, 10]),\n",
    "        \n",
    "    ], remainder='drop', verbose_feature_names_out=False)        # pipeline(memory='dirpath to cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = label_enc.fit_transform(ytrain)\n",
    "transformer.fit(Xtrain)\n",
    "Xtrain = transformer.transform(Xtrain)\n",
    "Xtest = transformer.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xval = train_test_split(Xtrain, test_size=0.2, shuffle=False)\n",
    "ytrain, yval = train_test_split(ytrain, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.shape, ytrain.shape, xval.shape, yval.shape, Xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping labels tensor to fit the model requirements of 2 dimensions\n",
    "ytrain = ytrain.reshape(ytrain.shape[0], 1)\n",
    "yval = yval.reshape(yval.shape[0], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix and distributions: \n",
    "(already at this phase it is presumed that the data is quite biased - \n",
    "looks like a fraud group from Rome, Italy found its way into the data and made many fraudulant \n",
    "transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.DataFrame(xtrain, columns=X.columns).corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (12,8))\n",
    "sns.heatmap(train_features,\n",
    "            cmap = \"coolwarm\",\n",
    "            annot = True,\n",
    "            annot_kws = {\"fontsize\":6, \"fontweight\":\"bold\"},\n",
    "            square = True,\n",
    "            linewidths = 1.0,\n",
    "            linecolor = \"white\",\n",
    "            ax = ax)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = -60)\n",
    "ax.set_title('Correlation Matrix ', fontsize = 10, fontweight = 'bold', color = 'darkblue')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import mlflow\n",
    "import datetime\n",
    "import os\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = Xtrain.shape[1]\n",
    "input_dim, Xtrain.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = {\n",
    "      'binary_crossentropy': keras.metrics.BinaryCrossentropy(name='binary_crossentropy'),  # same as model's loss\n",
    "      'Brier_score': keras.metrics.MeanSquaredError(name='Brier_score'),\n",
    "      'tp':keras.metrics.TruePositives(name='tp'),\n",
    "      'fp':keras.metrics.FalsePositives(name='fp'),\n",
    "      'tn':keras.metrics.TrueNegatives(name='tn'),\n",
    "      'fn':keras.metrics.FalseNegatives(name='fn'), \n",
    "      'accuracy':keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      'precision':keras.metrics.Precision(name='precision'),\n",
    "      'recall':keras.metrics.Recall(name='recall'),\n",
    "      'auc':keras.metrics.AUC(name='auc'),\n",
    "      'prc':keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.shape[0] + xval.shape[0] + Xtest.shape[0], data.shape[0], xtrain.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(metrics=METRICS, output_bias=None):\n",
    "    if output_bias:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(xtrain.shape[-1],)),\n",
    "        keras.layers.Dense(\n",
    "            16,\n",
    "            activation='relu',\n",
    "        ),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation='sigmoid',\n",
    "                           bias_initializer=output_bias),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3,),\n",
    "        loss=keras.losses.BinaryCrossentropy(),                 ### why does BinaryCrossentropy has a shape problem???????/\n",
    "        metrics=list(metrics.values())\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "eraly_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc',\n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "log_callback = tf.keras.callbacks.TensorBoard(#log_dir=logdir, \n",
    "                                    write_graph=True, \n",
    "                                    histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'EPOCHS' : 100,\n",
    "    'BATCH_SIZE': 2048,\n",
    "    #'callbacks': [eraly_stopping, log_callback]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils import plot_model\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testrun before training\n",
    "model.predict(xtrain[:10]).ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(xtrain, ytrain, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set an initial bias percentage in order to offset the bias in the data.\n",
    "This will be smoothed out with a log, which will decrease the inherant loss at the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(label_enc.transform(y))\n",
    "sum = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    sum, pos, 100 * pos / sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial bias (ofsetting the effect of biased dataset with less than 1% fraud cases)\n",
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(output_bias=initial_bias)\n",
    "model.predict(xtrain[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(xtrain, ytrain, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint weights\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights.weights.h5')\n",
    "model.save_weights(initial_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model from the saved weights, with initial bias 0\n",
    "model = create_model()\n",
    "model.load_weights(initial_weights)\n",
    "model.layers[-1].bias.assign([0.0])\n",
    "zero_bias_history = model.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    validation_data=(xval, yval),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model from saved weights with initial bias set.\n",
    "model = create_model()\n",
    "model.load_weights(initial_weights)\n",
    "careful_bias_history = model.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    batch_size=params['BATCH_SIZE'],\n",
    "    epochs=10,\n",
    "    validation_data=(xval, yval),\n",
    "    verbose=1,\n",
    "    callbacks=[log_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "careful_bias_history.history.keys()\n",
    "careful_bias_history.history['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "    plt.semilogy(history.epoch, history.history['loss'],\n",
    "                 color=colors[n], label='Train' + label)\n",
    "    plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "                 color=colors[n], label='val' + label,\n",
    "                 linestyle=\"--\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(zero_bias_history, 'Zero bias', 0)\n",
    "plot_loss(careful_bias_history, 'Careful bias', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names for MLFLOW runs\n",
    "experiment = 'baseline'\n",
    "run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "logdir = os.path.join(\"logs\", experiment, run_name)\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "model.load_weights(initial_weights)\n",
    "\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run: \n",
    "    mlflow.set_experiment_tag('baseline', 'fraud_analysis')    \n",
    "\n",
    "    baseline_history = model.fit(\n",
    "        xtrain,\n",
    "        ytrain,\n",
    "        batch_size=params['BATCH_SIZE'],\n",
    "        epochs=params['EPOCHS'],\n",
    "        callbacks=[eraly_stopping, log_callback],\n",
    "        validation_data=(xval, yval)\n",
    "    )\n",
    "    run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    mlflow.set_experiment_tag('baseline', 'fraud_analysis')\n",
    "    mlflow.set_tag(\"optimizer\", 'keras.optimizer.Adam')\n",
    "    mlflow.set_tag(\"loss\", \"binary_cross_entropy\")\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "    #mlflow.log_metrics(METRICS)\n",
    "    for key, value in METRICS.items(): \n",
    "        mlflow.log_metric(key, value)\n",
    "    mlflow.log_artifact(\"model.png\", \"model_plot\")\n",
    "\n",
    "    run_id = run.info.run_id\n",
    "    print(\"MLFlow Run ID: \", run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "    for i, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\", \" \")\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric], color=colors[0], linestyle='--', label=\"val\")\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.8, 1])\n",
    "        else:\n",
    "            plt.ylim([0, 1])\n",
    "\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(baseline_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_baseline = model.predict(xtrain, batch_size=BATCH_SIZE)\n",
    "test_pred_baseline = model.predict(Xtest, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = label_enc.transform(ytest)\n",
    "ytest = ytest.reshape(ytest.shape[0], 1)\n",
    "ytest.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, threshold=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > threshold)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.title(f'Confusion matrix @{threshold:.2f}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "\n",
    "    print('Legit transactions detected (True neg):', cm[0][0])\n",
    "    print('Legit transactions incorrect detected (False pos):', cm[0][1])\n",
    "    print('Fraud transactions missed (False neg):', cm[1][0])\n",
    "    print('Fraud transactions detected (True Pos):', cm[1][1])\n",
    "    print('Total fraud transactions:', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = model.evaluate(Xtest, ytest, batch_size=BATCH_SIZE, verbose=1)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "plot_cm(ytest, test_pred_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(ytest, test_pred_baseline, threshold=0.1)\n",
    "plot_cm(ytest, test_pred_baseline, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC - Receiver Operator Characteristic- \n",
    "#TPR vs FPR at various threshold values: separates the 'signal' from the 'noise'.)\n",
    "#true positive rate (TPR) on the Y axis, and false positive rate (FPR) on the X axis\n",
    "def plot_roc(name, labels, preds, **kwargs):        \n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, preds)            # _ for thresholds\n",
    "    #metrics.RocCurveDisplay.from_predictions(labels, preds, pos_label= 'Detected Fraud', name=name)\n",
    "    print(len(fpr))\n",
    "   \n",
    "    print(len(tpr))\n",
    "    plt.plot(100*fpr, 100*tpr, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.xlim([-0.5,25])\n",
    "    plt.ylim([80,100.5])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    return fpr, tpr\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fp, train_tp = plot_roc('Train Baseline', ytrain, train_pred_baseline, color=colors[0])\n",
    "test_fp, test_tp = plot_roc('Test baseline', ytest, test_pred_baseline, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot area under the curve: AUPRC - area under the percision-recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prc(name, labels, preds, **kwargs):\n",
    "    precision, recall, _ = metrics.precision_recall_curve(labels, preds)\n",
    "\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prc('Train baseline', ytrain, train_pred_baseline, color=colors[0])\n",
    "plot_prc('Test baseline', ytest, test_pred_baseline, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_0 = (1 / neg) * (sum / 2.0)\n",
    "weight_1 = (1 / pos) * (sum / 2.0)\n",
    "\n",
    "class_weight = {0: weight_0, 1: weight_1}\n",
    "\n",
    "print(f'weight class 0: {weight_0:.2f}')\n",
    "print(f'weight class 1: {weight_1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with class weight: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_model = create_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[eraly_stopping],\n",
    "    validation_data=(xval, yval),\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(weighted_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_weighted = weighted_model.predict(xtrain, batch_size=BATCH_SIZE)\n",
    "test_pred_weighted = weighted_model.predict(Xtest, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_baseline.shape, train_pred_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_results = weighted_model.evaluate(Xtest, ytest, batch_size=BATCH_SIZE, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "plot_cm(ytest, test_pred_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc('Train baseline', ytrain, train_pred_baseline, color=colors[0])\n",
    "plot_roc('Train baseline', ytest, test_pred_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_roc('Test weighted', ytrain, train_pred_weighted, color=colors[1])\n",
    "plot_roc('Test weighted', ytest, test_pred_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prc('Train baseline', ytrain, train_pred_baseline, color=colors[0])\n",
    "plot_prc('Train baseline', ytest, test_pred_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_prc('Test weighted', ytrain, train_pred_weighted, color=colors[1])\n",
    "plot_prc('Test weighted', ytest, test_pred_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
