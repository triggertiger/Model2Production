{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- include timestamp as feature - done\n",
    "- shuffle dataset - shuffle so that each set has frauds (stratify) - done\n",
    "- separate 'retraining set' for the cloud updates \n",
    "- Data processing: change names of columns, create time stamp, delete 'time' column, train test split, stratify, apply encoding pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ibm_4y.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCC codes are four-digit numbers that classify a business by the services it provides or products it sells. If a business has a variety of products or services, the MCC code is usually based on the product or service that makes up the bulk of the businessâ€™ sales. (https://www.heartland.us/resources/blog/merchants-guide-to-mcc-codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(str.lower, axis='columns', inplace=True)\n",
    "data.rename(columns={'use chip': 'use_chip', \n",
    "                       'merchant name': 'merchant_name', \n",
    "                       'merchant city': 'merchant_city', \n",
    "                       'merchant state': 'merchant_state',\n",
    "                       'errors?': 'errors', \n",
    "                       'is fraud?': 'is_fraud' }, \n",
    "                       inplace=True)\n",
    "# set time series index\n",
    "data[['hour', 'minute']] = data['time'].str.split(':', expand=True)\n",
    "data['date'] = pd.to_datetime(data[['year', 'month', 'day', 'hour', 'minute']])\n",
    "data.set_index('date', inplace=True)\n",
    "data.sort_index(inplace=True)\n",
    "\n",
    "data.drop(columns=[ 'time'], inplace=True)\n",
    "# convert amount to float\n",
    "data['amount'] = data['amount'].str[1:].astype('float64')\n",
    "\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - coding and normalizing \n",
    "\n",
    "Train tess split: since 2020 is not a full year, test data will be taken out of 2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['is_fraud'])\n",
    "y = data[['is_fraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, xtest, Ytrain, ytest = train_test_split(X, \n",
    "                                                y, \n",
    "                                                test_size=0.2,      #test size default 25%\n",
    "                                                random_state=42, \n",
    "                                                shuffle=True, \n",
    "                                                stratify=y)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xval, ytrain, yval = train_test_split(Xtrain, \n",
    "                                                Ytrain, \n",
    "                                                test_size=0.25, \n",
    "                                                random_state=42, \n",
    "                                                shuffle=True, \n",
    "                                                stratify=Ytrain)     #test size default 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "# replace missing values with a constant text, then encode to numeric classes and scale\n",
    "state_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='online')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# replace missing values with zero, then encode and scale\n",
    "zero_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# implement number scaler on numerical features (no missing values)\n",
    "# implement text replacement to state and errors\n",
    "# implement zero replacement to zip, city and chip\n",
    "transformer= ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('number_scaler', StandardScaler(), [0, 1, 2, 3, 4, 5, 7, 11, 13, 14]),\n",
    "        ('NAN_replace_text', state_pipe, [9, 12]),\n",
    "        ('NAN_replace_zero', zero_pipe, [6, 8, 10]),\n",
    "        \n",
    "    ], remainder='drop', verbose_feature_names_out=False)        # pipeline(memory='dirpath to cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = label_enc.fit_transform(ytrain)\n",
    "yval = label_enc.fit_transform(yval)\n",
    "transformer.fit(xtrain)\n",
    "xtrain = transformer.transform(xtrain)\n",
    "xval = transformer.transform(xval)\n",
    "xtest = transformer.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping labels tensor to fit the model requirements of 2 dimensions\n",
    "ytrain = ytrain.reshape(ytrain.shape[0], 1)\n",
    "yval = yval.reshape(yval.shape[0], 1)\n",
    "ytrain.ndim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix and distributions: \n",
    "(already at this phase it is presumed that the data is quite biased - \n",
    "looks like a fraud group from Rome, Italy found its way into the data and made many fraudulant \n",
    "transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variables to play with \n",
    "- shuffle/ unshuffle\n",
    "- number of layers\n",
    "- size of layers\n",
    "- dropout\n",
    "- epochs\n",
    "- use standard scaler\n",
    "- use standardization instead of scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = xtrain.shape[1]\n",
    "input_dim, xtrain.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = {\n",
    "      'binary_crossentropy': keras.metrics.BinaryCrossentropy(name='binary_crossentropy'),  # same as model's loss\n",
    "      'Brier_score': keras.metrics.MeanSquaredError(name='Brier_score'),\n",
    "      'tp':keras.metrics.TruePositives(name='tp'),\n",
    "      'fp':keras.metrics.FalsePositives(name='fp'),\n",
    "      'tn':keras.metrics.TrueNegatives(name='tn'),\n",
    "      'fn':keras.metrics.FalseNegatives(name='fn'), \n",
    "      'accuracy':keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      'precision':keras.metrics.Precision(name='precision'),\n",
    "      'recall':keras.metrics.Recall(name='recall'),\n",
    "      'auc':keras.metrics.AUC(name='auc'),\n",
    "      'prc':keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.shape[0] + xval.shape[0] + xtest.shape[0], data.shape[0], xtrain.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial bias for balancing negative and positive classes: \n",
    "neg, pos = np.bincount(label_enc.transform(y))\n",
    "sum = neg + pos\n",
    "\n",
    "initial_bias = np.log([pos/neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 1e-3,\n",
    "    'initial_bias': initial_bias,\n",
    "    'dropout': 0.5,\n",
    "    'layer1_size': 16,\n",
    "    'activation1': 'relu'\n",
    "    #'callbacks': [eraly_stopping, log_callback]\n",
    "    }\n",
    "\n",
    "train_params = {\n",
    "    'patience': 10,\n",
    "    'epochs' : 100,\n",
    "    'batch_size': 2048,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(metrics=METRICS, output_bias=None, params=params):\n",
    "    if output_bias:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(xtrain.shape[-1],)),\n",
    "        keras.layers.Dense(\n",
    "            params['layer1_size'],\n",
    "            activation=params['activation1'],\n",
    "        ),\n",
    "        keras.layers.Dropout(params['dropout']),\n",
    "        keras.layers.Dense(1, activation='sigmoid',\n",
    "                           bias_initializer=output_bias),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
    "        loss=keras.losses.BinaryCrossentropy(),                 ### why does BinaryCrossentropy has a shape problem???????/\n",
    "        metrics=list(metrics.values())\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eraly_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc',\n",
    "    verbose=1,\n",
    "    patience=train_params['patience'],\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testrun before training\n",
    "model.predict(xtrain[:10]).ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(xtrain, ytrain, batch_size=params['batch_size'], verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set an initial bias percentage in order to offset the bias in the data.\n",
    "This will be smoothed out with a log, which will decrease the inherant loss at the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(output_bias=params['initial_bias'])\n",
    "model.predict(xtrain[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(xtrain, ytrain, batch_size=params['batch_size'], verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint weights\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights.weights.h5')\n",
    "model.save_weights(initial_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model from the saved weights, with initial bias 0\n",
    "model = create_model()\n",
    "model.load_weights(initial_weights)\n",
    "model.layers[-1].bias.assign([0.0])\n",
    "zero_bias_history = model.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    batch_size=params['batch_size'],\n",
    "    epochs=5,\n",
    "    validation_data=(xval, yval),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names for MLFLOW runs\n",
    "experiment = 'baseline'\n",
    "run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "logdir = os.path.join(\"logs\", experiment, run_name)\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "log_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, \n",
    "                                    write_graph=True, \n",
    "                                    histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model from saved weights with initial bias set.\n",
    "model = create_model()\n",
    "model.load_weights(initial_weights)\n",
    "careful_bias_history = model.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    batch_size=params['batch_size'],\n",
    "    epochs=5,\n",
    "    validation_data=(xval, yval),\n",
    "    verbose=1,\n",
    "    callbacks=[eraly_stopping, log_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "careful_bias_history.history.keys()\n",
    "careful_bias_history.history['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = mlflow.set_tracking_uri(\"./mlruns\")\n",
    "uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names for MLFLOW runs\n",
    "experiment = 'tensorboard'\n",
    "run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "logdir = os.path.join(\"logs\", experiment, run_name)\n",
    "\n",
    "#os.makedirs(f'{logdir}/models', exist_ok=True)\n",
    "\n",
    "# for tensorboard logging -\n",
    "log_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, \n",
    "                                    write_graph=True, \n",
    "                                    histogram_freq=1)\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "model.load_weights(initial_weights)\n",
    "#mlflow.keras.autolog(registered_model_name='initial_bias')\n",
    "\n",
    "mlflow.set_experiment('baseline')\n",
    "with mlflow.start_run(run_name=run_name) as run: \n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    mlflow.set_experiment_tag('baseline', 'fraud_analysis')    \n",
    "    #\n",
    "    mlflow.tensorflow.log_model(model, \"models\")\n",
    "    #mlflow.tensorflow.autolog(disable=True)\n",
    "    baseline_history = model.fit(\n",
    "            xtrain,\n",
    "            ytrain,\n",
    "            batch_size=params['batch_size'],\n",
    "            #epochs=2,\n",
    "            epochs=params['epochs'],\n",
    "            callbacks=[eraly_stopping, mlflow.tensorflow.MlflowCallback(run)],  #log_callback, \n",
    "            validation_data=(xval, yval)\n",
    "        )\n",
    "    \n",
    "    run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_baseline = model.predict(xtrain, batch_size=params['batch_size'])\n",
    "test_pred_baseline = model.predict(xtest, batch_size=params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = label_enc.transform(ytest)\n",
    "ytest = ytest.reshape(ytest.shape[0], 1)\n",
    "ytest.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, threshold=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > threshold)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.title(f'Confusion matrix @{threshold:.2f}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "\n",
    "    print('Legit transactions detected (True neg):', cm[0][0])\n",
    "    print('Legit transactions incorrect detected (False pos):', cm[0][1])\n",
    "    print('Fraud transactions missed (False neg):', cm[1][0])\n",
    "    print('Fraud transactions detected (True Pos):', cm[1][1])\n",
    "    print('Total fraud transactions:', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = model.evaluate(Xtest, ytest, batch_size=BATCH_SIZE, verbose=1)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "plot_cm(ytest, test_pred_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(ytest, test_pred_baseline, threshold=0.1)\n",
    "plot_cm(ytest, test_pred_baseline, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC - Receiver Operator Characteristic- \n",
    "#TPR vs FPR at various threshold values: separates the 'signal' from the 'noise'.)\n",
    "#true positive rate (TPR) on the Y axis, and false positive rate (FPR) on the X axis\n",
    "def plot_roc(name, labels, preds, **kwargs):        \n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, preds)            # _ for thresholds\n",
    "    #metrics.RocCurveDisplay.from_predictions(labels, preds, pos_label= 'Detected Fraud', name=name)\n",
    "    print(len(fpr))\n",
    "   \n",
    "    print(len(tpr))\n",
    "    plt.plot(100*fpr, 100*tpr, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.xlim([-0.5,25])\n",
    "    plt.ylim([80,100.5])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    return fpr, tpr\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fp, train_tp = plot_roc('Train Baseline', ytrain, train_pred_baseline, color=colors[0])\n",
    "test_fp, test_tp = plot_roc('Test baseline', ytest, test_pred_baseline, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot area under the curve: AUPRC - area under the percision-recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prc(name, labels, preds, **kwargs):\n",
    "    precision, recall, _ = metrics.precision_recall_curve(labels, preds)\n",
    "\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prc('Train baseline', ytrain, train_pred_baseline, color=colors[0])\n",
    "plot_prc('Test baseline', ytest, test_pred_baseline, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_0 = (1 / neg) * (sum / 2.0)\n",
    "weight_1 = (1 / pos) * (sum / 2.0)\n",
    "\n",
    "class_weight = {0: weight_0, 1: weight_1}\n",
    "\n",
    "print(f'weight class 0: {weight_0:.2f}')\n",
    "print(f'weight class 1: {weight_1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with class weight: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_model = create_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[eraly_stopping],\n",
    "    validation_data=(xval, yval),\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(weighted_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_weighted = weighted_model.predict(xtrain, batch_size=BATCH_SIZE)\n",
    "test_pred_weighted = weighted_model.predict(Xtest, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_baseline.shape, train_pred_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_results = weighted_model.evaluate(Xtest, ytest, batch_size=BATCH_SIZE, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "plot_cm(ytest, test_pred_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc('Train baseline', ytrain, train_pred_baseline, color=colors[0])\n",
    "plot_roc('Train baseline', ytest, test_pred_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_roc('Test weighted', ytrain, train_pred_weighted, color=colors[1])\n",
    "plot_roc('Test weighted', ytest, test_pred_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prc('Train baseline', ytrain, train_pred_baseline, color=colors[0])\n",
    "plot_prc('Train baseline', ytest, test_pred_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_prc('Test weighted', ytrain, train_pred_weighted, color=colors[1])\n",
    "plot_prc('Test weighted', ytest, test_pred_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
