{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with the model: \n",
    "using MLFlow to make first attempts with the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/ibm_4y.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(data):\n",
    "    \"\"\" processes the dataframe columns to desired format\"\"\"\n",
    "\n",
    "    data.rename(str.lower, axis='columns', inplace=True)\n",
    "    data.rename(columns={'use chip': 'use_chip', \n",
    "                        'merchant name': 'merchant_name', \n",
    "                        'merchant city': 'merchant_city', \n",
    "                        'merchant state': 'merchant_state',\n",
    "                        'errors?': 'errors', \n",
    "                        'is fraud?': 'is_fraud' }, \n",
    "                        inplace=True)\n",
    "    # set time series index\n",
    "    data[['hour', 'minute']] = data['time'].str.split(':', expand=True)\n",
    "    data['date'] = pd.to_datetime(data[['year', 'month', 'day', 'hour', 'minute']])\n",
    "    data.set_index('date', inplace=True)\n",
    "    data.sort_index(inplace=True)\n",
    "\n",
    "    data.drop(columns=[ 'time'], inplace=True)\n",
    "    \n",
    "    # convert amount to float\n",
    "    data['amount'] = data['amount'].str[1:].astype('float64')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - coding and normalizing \n",
    "\n",
    "Train test split: including shuffle and stratify - since this is not a time series and there is no dependency between the datapoints. \n",
    "stratify - include positive class in every split equally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_spliter(data):\n",
    "    \"\"\" takes fraud dataframe, performs train_test_split and applies scaling and encoding to features and labels\n",
    "    performs initial bias calculation for the imbalanced dataset.\n",
    "    returns xtrain, ytrain, xval, yval, xtest, ytest and initial bias\"\"\"\n",
    "\n",
    "    # split to x (features) and y (labels), and split twice (train, val, test)\n",
    "    X = data.drop(columns=['is_fraud'])\n",
    "    y = data[['is_fraud']]\n",
    "    Xtrain, xtest, Ytrain, ytest = train_test_split(X, \n",
    "                                                y, \n",
    "                                                test_size=0.2,      #test size default 25%\n",
    "                                                random_state=42, \n",
    "                                                shuffle=True, \n",
    "                                                stratify=y) \n",
    "    xtrain, xval, ytrain, yval = train_test_split(Xtrain, \n",
    "                                                Ytrain, \n",
    "                                                test_size=0.25, \n",
    "                                                random_state=42, \n",
    "                                                shuffle=True, \n",
    "                                                stratify=Ytrain)   \n",
    "    \n",
    "    label_enc = LabelEncoder()\n",
    "\n",
    "    # replace missing values with a constant text, then encode to numeric classes and scale\n",
    "    state_pipe = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='online')),\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    # replace missing values with zero, then encode and scale\n",
    "    zero_pipe = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # implement number scaler on numerical features (no missing values)\n",
    "    # implement text replacement to state and errors\n",
    "    # implement zero replacement to zip, city and chip\n",
    "    transformer= ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('number_scaler', StandardScaler(), [0, 1, 2, 3, 4, 5, 7, 11, 13, 14]),\n",
    "            ('NAN_replace_text', state_pipe, [9, 12]),\n",
    "            ('NAN_replace_zero', zero_pipe, [6, 8, 10]),\n",
    "            \n",
    "        ], remainder='drop', verbose_feature_names_out=False)  \n",
    "    \n",
    "    # apply label encoder on labels: \n",
    "    ytrain = label_enc.fit_transform(ytrain)\n",
    "    yval = label_enc.fit_transform(yval)\n",
    "    ytest = label_enc.transform(ytest)\n",
    "\n",
    "    # apply pipeline on feature values\n",
    "    transformer.fit(xtrain)\n",
    "    xtrain = transformer.transform(xtrain)\n",
    "    xval = transformer.transform(xval)\n",
    "    xtest = transformer.transform(xtest)\n",
    "    \n",
    "    # set output bias with the fitted data encoder -\n",
    "    # output bias is added as a constant matrix to the output layer of the model\n",
    "    # and multiply the results to counter act the imbalance of the data classes\n",
    "    neg, pos = np.bincount(label_enc.transform(y))\n",
    "    sum = neg + pos\n",
    "    initial_bias = np.log([pos/neg])\n",
    "    \n",
    "    # reshaping labels tensor to fit the model requirements of 2 dimensions\n",
    "    ytrain = ytrain.reshape(ytrain.shape[0], 1)\n",
    "    yval = yval.reshape(yval.shape[0], 1)\n",
    "\n",
    "    return xtrain, ytrain, xval, yval, xtest, ytest, initial_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker( metrics,  params):\n",
    "    \"\"\"builds a keras sequential from the params \"\"\"\n",
    "    \n",
    "    output_bias = params['output_bias']\n",
    "    if output_bias:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = keras.Sequential([keras.Input(shape=params['train_feature_size'])])\n",
    "    for l in range(params['nr_of_layers']):\n",
    "        layer = keras.layers.Dense(\n",
    "            params['layer_size'][l],\n",
    "            activation=params['activation1'],\n",
    "            name=f'Denselayer{l+1}'\n",
    "        )\n",
    "        model.add(layer)\n",
    "    \n",
    "    model.add(keras.layers.Dropout(params['dropout']))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid',\n",
    "                           bias_initializer=output_bias))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
    "        loss=keras.losses.BinaryCrossentropy(),               \n",
    "        metrics=list(metrics.values())\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(metrics, params, train_params, train_ds, val_ds, callback=None):\n",
    "    \"\"\"fix training according to the training params with the relevant sklearn metrics. \n",
    "    set early stopping callback, and other callbacs, if mentioned (relevant for loading initial weights).\n",
    "    returns: model for training.\"\"\"\n",
    "    model = model_maker(metrics, params)\n",
    "    \n",
    "    eraly_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_prc',\n",
    "        verbose=1,\n",
    "        patience=train_params['patience'],\n",
    "        mode='max',\n",
    "        restore_best_weights=True\n",
    "        )\n",
    "    \n",
    "    # set callbacks:\n",
    "    callbacks_list = [eraly_stopping]\n",
    "    if callback:\n",
    "        callbacks_list.append(callback)\n",
    "    try:\n",
    "        initial_weights= train_params['initial_weights']\n",
    "    \n",
    "    # handle: if no weights are saved/loaded - tensorflow saves initial weights in tempfile. \n",
    "    except KeyError:\n",
    "        \n",
    "        train_params['initial_weights'] = os.path.join(tempfile.mkdtemp(), 'initial_weights.weights.h5')\n",
    "        model.save_weights(train_params['initial_weights']) \n",
    "        print('weights saved')\n",
    "        initial_weights= train_params['initial_weights']\n",
    "        print(f'initial waights created: {initial_weights}')\n",
    "    model.load_weights(initial_weights)\n",
    "    \n",
    "    if params['output_bias'] is None:\n",
    "        \n",
    "        model.layers[-1].bias.assign([0.0])\n",
    "    \n",
    "    # fit model to train and eval datasets:\n",
    "    model.fit(\n",
    "        train_ds, \n",
    "        batch_size=train_params['batch_size'],\n",
    "        epochs=train_params['epochs'],\n",
    "        validation_data=val_ds,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "      'binary_crossentropy': keras.metrics.BinaryCrossentropy(name='binary_crossentropy'), \n",
    "      'Brier_score': keras.metrics.MeanSquaredError(name='Brier_score'),\n",
    "      'tp':keras.metrics.TruePositives(name='tp'),\n",
    "      'fp':keras.metrics.FalsePositives(name='fp'),\n",
    "      'tn':keras.metrics.TrueNegatives(name='tn'),\n",
    "      'fn':keras.metrics.FalseNegatives(name='fn'), \n",
    "      'accuracy':keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      'precision':keras.metrics.Precision(name='precision'),\n",
    "      'recall':keras.metrics.Recall(name='recall'),\n",
    "      'auc':keras.metrics.AUC(name='auc'),\n",
    "      'prc':keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "}\n",
    "\n",
    "\n",
    "params = {\n",
    "    # logging: raise warning if the number of items in the list layer size \n",
    "    # is not smaller than the number of layers.\n",
    "    'learning_rate': 1e-3,\n",
    "    'output_bias': None,\n",
    "    'dropout': 0.5,\n",
    "    'train_feature_size': 15,   # =(xtrain.shape[-1],)),\n",
    "    'layer_size': [16, 16, 32, 16],\n",
    "    'activation1': 'relu',\n",
    "    'nr_of_layers': 4\n",
    "    }\n",
    "\n",
    "train_params = {\n",
    "    'patience': 10,\n",
    "    'epochs' : 100,\n",
    "    'batch_size': 2048,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_prep(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain, xval, yval, xtest, ytest, initial_bias = data_spliter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['output_bias'] = initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for TF logging: (examples.batch(20).prefetch(2) will prefetch 2 elements (2 batches, of 20 examples each).)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((xtrain, ytrain)).batch(train_params['batch_size']).prefetch(2)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((xval, yval)).batch(train_params['batch_size']).prefetch(2)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((xtest, ytest)).batch(train_params['batch_size']).prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: \n",
    "model = model_maker(model_metrics, params)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer(model_metrics, params, train_params, train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run(name, params, train_params, metrics, train_ds, val_ds, test_ds, run_name=None):\n",
    "    \"\"\"\n",
    "    calls  model_maker and model_trainer functions, with MLFlow wrapper and params.\n",
    "     tracks different model runs in experiments on mlrun server \"\"\"\n",
    "    tags = {k: v for k, v in params.items()}\n",
    "    \n",
    "    mlflow.set_experiment(name)\n",
    "    experiment = mlflow.get_experiment_by_name(name)\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    run = client.create_run(experiment.experiment_id)        \n",
    "    mlflow.tensorflow.autolog(disable=True)\n",
    "    with mlflow.start_run(run_name=run_name) as run: \n",
    "        logging_callback =  mlflow.tensorflow.MlflowCallback(run)\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_params(train_params)\n",
    "        mlflow.set_tags(tags)\n",
    "        \n",
    "        model = trainer(metrics, params, train_params, train_ds, val_ds, logging_callback)\n",
    "        results = model.evaluate(test_ds, batch_size=train_params['batch_size'], verbose=1)\n",
    "        predictions = model.predict(test_ds, batch_size=train_params['batch_size'])\n",
    "        for name, value in zip(model.metrics_names, results):\n",
    "            print(name, ': ', value)\n",
    "        print(predictions)\n",
    "        mlflow.tensorflow.log_model(model, \"models\")\n",
    "\n",
    "\n",
    "        cm = ConfusionMatrixDisplay.from_predictions(\n",
    "            np.concatenate([y for x, y in test_ds], axis=0), predictions > 0.2)\n",
    "        \n",
    "        mlflow.log_figure(cm.figure_, 'test_confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_run('zero_bias', params, train_params, model_metrics, train_ds, val_ds, test_ds, run_name='2 layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params['initial_weights']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "params view: \n",
    "params = {\n",
    "    'learning_rate': 1e-3,\n",
    "    'output_bias': None,\n",
    "    'dropout': 0.5,\n",
    "    'train_feature_size': 15,  \n",
    "    'layer1_size': 16,\n",
    "    'activation1': 'relu',\n",
    "    'callbacks': []\n",
    "    }\n",
    "\n",
    "train_params = {\n",
    "    'patience': 10,\n",
    "    'epochs' : 100,   \n",
    "    'batch_size': 2048,\n",
    "    #'initial_weights': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['output_bias'] = initial_bias\n",
    "params['nr_of_layers'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test without output bias\n",
    "train_pred_baseline = model.predict(xtrain, batch_size=params['batch_size'])\n",
    "test_pred_baseline = model.predict(xtest, batch_size=params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, threshold=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > threshold)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.title(f'Confusion matrix @{threshold:.2f}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "\n",
    "    print('Legit transactions detected (True neg):', cm[0][0])\n",
    "    print('Legit transactions incorrect detected (False pos):', cm[0][1])\n",
    "    print('Fraud transactions missed (False neg):', cm[1][0])\n",
    "    print('Fraud transactions detected (True Pos):', cm[1][1])\n",
    "    print('Total fraud transactions:', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = model.evaluate(Xtest, ytest, batch_size=BATCH_SIZE, verbose=1)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "plot_cm(ytest, test_pred_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(ytest, test_pred_baseline, threshold=0.1)\n",
    "plot_cm(ytest, test_pred_baseline, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC - Receiver Operator Characteristic- \n",
    "#TPR vs FPR at various threshold values: separates the 'signal' from the 'noise'.)\n",
    "#true positive rate (TPR) on the Y axis, and false positive rate (FPR) on the X axis\n",
    "def plot_roc(name, labels, preds, **kwargs):        \n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, preds)            # _ for thresholds\n",
    "    #metrics.RocCurveDisplay.from_predictions(labels, preds, pos_label= 'Detected Fraud', name=name)\n",
    "    print(len(fpr))\n",
    "   \n",
    "    print(len(tpr))\n",
    "    plt.plot(100*fpr, 100*tpr, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.xlim([-0.5,25])\n",
    "    plt.ylim([80,100.5])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    return fpr, tpr\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fp, train_tp = plot_roc('Train Baseline', ytrain, train_pred_baseline, color=colors[0])\n",
    "test_fp, test_tp = plot_roc('Test baseline', ytest, test_pred_baseline, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot area under the curve: AUPRC - area under the percision-recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prc(name, labels, preds, **kwargs):\n",
    "    precision, recall, _ = metrics.precision_recall_curve(labels, preds)\n",
    "\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prc('Train baseline', ytrain, train_pred_baseline, color=colors[0])\n",
    "plot_prc('Test baseline', ytest, test_pred_baseline, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_0 = (1 / neg) * (sum / 2.0)\n",
    "weight_1 = (1 / pos) * (sum / 2.0)\n",
    "\n",
    "class_weight = {0: weight_0, 1: weight_1}\n",
    "\n",
    "print(f'weight class 0: {weight_0:.2f}')\n",
    "print(f'weight class 1: {weight_1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with class weight: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_model = create_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[eraly_stopping],\n",
    "    validation_data=(xval, yval),\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(weighted_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_weighted = weighted_model.predict(xtrain, batch_size=BATCH_SIZE)\n",
    "test_pred_weighted = weighted_model.predict(Xtest, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_baseline.shape, train_pred_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_results = weighted_model.evaluate(Xtest, ytest, batch_size=BATCH_SIZE, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "plot_cm(ytest, test_pred_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc('Train baseline', ytrain, train_pred_baseline, color=colors[0])\n",
    "plot_roc('Train baseline', ytest, test_pred_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_roc('Test weighted', ytrain, train_pred_weighted, color=colors[1])\n",
    "plot_roc('Test weighted', ytest, test_pred_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prc('Train baseline', ytrain, train_pred_baseline, color=colors[0])\n",
    "plot_prc('Train baseline', ytest, test_pred_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_prc('Test weighted', ytrain, train_pred_weighted, color=colors[1])\n",
    "plot_prc('Test weighted', ytest, test_pred_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATES = {'dates': \n",
    "               pd.Series(pd.to_datetime(pd.date_range('2019-01-01','2020-02-01',freq='MS').strftime(\"%b-%y\").tolist(), format='%b-%y'\n",
    "))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATES['dates'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/clean_cc_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "short = df[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short.reset_index(inplace=True)\n",
    "short.rename(columns={'index': 'time_stamp'})\n",
    "short.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
